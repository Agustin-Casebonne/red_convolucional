| Prueba   | Modelo                         | Capas Descongeladas          | Optimizador | Tasa de Aprendizaje (lr) | Data Augmentation | Resultado (Test Acc.) | Notas                                                                                                   |
|----------|----------------------------------|-------------------------------|-------------|----------------------------|--------------------|------------------------|---------------------------------------------------------------------------------------------------------|
| Prueba 1 | AnimalNet (CNN simple)           | N/A                           | SGD         | 0.01                       | No                 | 67.67%                 | Configuración base.                                                                                     |
| Prueba 2 | AnimalNet (CNN simple)           | N/A                           | Adam        | 0.001                      | Sí                 | 69%                    | Uso del optimizador Adam y Data Augmentation (opcional).                                                |
| Prueba 3 | ResNetTransfer (ResNet-18)       | Solo FC                       | Adam        | 0.0001                     | Sí                 | 70.01%                 | Transfer Learning básico: se congela el extractor de características y se entrena solo la capa FC.     |
| Prueba 4 | ResNetTransferFineTune           | FC + Layer 4                  | Adam        | 1×10⁻⁵                    | Sí                 | 78%                    | Fine-Tuning intermedio: se entrena la capa FC y el último bloque convolucional (Layer 4).               |
| Prueba 5 | ResNetTransferFineTuneDeeper     | FC + Layer 3 + Layer 4        | Adam        | 5×10⁻⁵                    | Sí                 | 82.17%             | Fine-Tuning profundo: se entrenan la capa FC y los bloques Layer 3 y Layer 4. Se espera mejor rendimiento. |
